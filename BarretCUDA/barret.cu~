// This file is part of BarretCUDA v0.1 
// 
// BarretCUDA is a fast(ish) CUDA implementation of sparse matrix
// multiplication modulo a multi-precision prime.
// 
// Copyright (C) 2016, Ryan Henry and Syed Mahbub Hafiz
// 
// 
// BarretCUDA is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published
// by the Free Software Foundation, either version 3 of the License,
// or (at your option) any later version.
// 
// BarretCUDA is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
// 
// You should have received a copy of the GNU General Public License
// along with BarretCUDA.  If not, see <http://www.gnu.org/licenses/>.

#include <atomic>
#include <chrono>
#include <ratio>
#include <fstream>

#include "barret.h"
#include "uintX.h"

#define NUM_BLOCKS 		1//256
#define THREADS_PER_BLOCK(n)	((n + NUM_BLOCKS - 1) / NUM_BLOCKS)

NTL_CLIENT

template <typename T>
__global__ void SpMV_kernel(T * response, uint * o, const T * query, const uint nvals,
	const T * vals, const uint ncols, const uint * cols, const uint * rows,
	const T * modulus, const T * mu, const T * subtrahends)
{
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i >= ncols) return;

    response[i] = { 0 };
    T hi = { 0 };
    uint overflow = { 0 };
    for (int j = cols[i]; j < cols[i+1]; ++j)
    {
	mad(response[i], hi, overflow, vals[j], query[rows[j]]);
    }
//if (i==1) {printf("\n  a:\t"); _print_limbs<T>(response[i]);}
//if (i==1) {printf("\n  overflow:\t%u", overflow); }
    normalize(response[i], hi, subtrahends[2*overflow], subtrahends[2*overflow+1]);
//if (i==1) {printf("\n  a':\t"); _print_limbs<T>(response[i]);}
    uintXp<T> q = get_q(response[i], hi, *mu);
//if (i==1) {printf("\n  q:\t"); _print_limbs<T>(q.lo);}
    uintXp<T> r2 = get_r2(q, *modulus);
//if (i==1) {printf("\n  r2:\t"); _print_limbs<T>(r2.lo);}
    o[i] = sub(response[i], hi, r2);
//if (i==1) {printf("\n  a'':\t"); _print_limbs<T>(response[i]);}
}

template <typename T>
void SpMV_ntl(NTL::vec_ZZ_p & response, const T * query,
	const SparseMatrix<T> & matrix)
{
cout << "\n\nSpMV_ntl:";
    for (int i = 0; i < matrix.ncols; i++)
    {
	response[i] = NTL::to_ZZ_p(0);
	for (int j = matrix.l_cols[i]; j < matrix.l_cols[i+1]; ++j)
	{
	    response[i] += to_ZZ_p(matrix.l_vals[j]) * to_ZZ_p(query[matrix.l_rows[j]]);
	}
cout << "\n  a''':\t"; print_limbs<T>(response[i]);
    }
}

template <typename T>
void SpMV_ntl_barret(NTL::vec_ZZ_p & response, const T * query,
	const SparseMatrix<T> & matrix, struct BarretParams<T> & barret)
{
cout << "\n\nSpMV_ntl_barret:";
    NTL::vec_ZZ response_ZZ(INIT_SIZE, matrix.ncols);
    for (int i = 0; i < matrix.ncols; i++)
    {
	response_ZZ[i] = NTL::to_ZZ(0);

	for (int j = matrix.l_cols[i]; j < matrix.l_cols[i+1]; ++j)
	{
	    response_ZZ[i] += to_ZZ(matrix.l_vals[j]) * to_ZZ(query[matrix.l_rows[j]]);
	}
//if (i==1) {cout << "\n  a:\t"; print_limbs<T>(response_ZZ[i]);}
	int overflow = (int)trunc_long(response_ZZ[i] >> 2*BITS_IN(LIMBS_IN(T)), 32);
//if (i==1) {cout << "\n  overflow:\t" << overflow;}
	response_ZZ[i] -= barret.l_subtrahends[overflow];
//if (i==1) {cout << "\n  a':\t"; print_limbs<T>(response_ZZ[i]);}

	NTL::ZZ q1 = response_ZZ[i] >> BITS_IN(LIMBS_IN(T)-1);
	NTL::ZZ q2 = q1 * barret.l_mu;
	NTL::ZZ q3 = q2 >> BITS_IN(LIMBS_IN(T)+1);
//if (i==1) {cout << "\n  q:\t"; print_limbs<T>(q3);}
	NTL::ZZ r1 = response_ZZ[i] % power2_ZZ(BITS_IN(LIMBS_IN(T)+1));
	NTL::ZZ r2 = q3 * barret.l_modulus % power2_ZZ(BITS_IN(LIMBS_IN(T)+1));
//if (i==1) {cout << "\n  r2:\t"; print_limbs<T>(r2);}
	NTL::ZZ r = (r1 - r2) % power2_ZZ(BITS_IN(LIMBS_IN(T)+1));
//if (i==1) {cout << "\n  a'':\t"; print_limbs<T>(r);}
	response[i] = NTL::to_ZZ_p(r);
	cout << "\n  a''':\t"; print_limbs<T>(response[i]);
    }
}

template <typename T>
void SpMV(NTL::vec_ZZ_p & response, T * l_response, const T * l_query,
	T * d_response,	T * d_query, const cudaStream_t & stream,
	const SparseMatrix<T> & matrix, const BarretParams<T> & barret)
{
printf("\n\nSpMV_kernel:");
    cudaMemcpy(d_query, l_query, matrix.nrows * sizeof(T),
	cudaMemcpyHostToDevice);

    const dim3 Dg(NUM_BLOCKS, 1, 1);
    const dim3 Db(THREADS_PER_BLOCK(matrix.ncols), 1, 1);
    const size_t Ns = 0;

uint * l_o = (uint *)malloc(matrix.ncols * sizeof(uint)), *d_o;
cudaMalloc((void**)&d_o, matrix.ncols * sizeof(uint));

    SpMV_kernel<T> <<< Dg, Db, Ns, stream >>> (d_response, d_o, d_query,
	matrix.nvals, matrix.d_vals, matrix.ncols, matrix.d_cols, matrix.d_rows,
	barret.d_modulus, barret.d_mu, barret.d_subtrahends);
cudaMemcpyAsync(l_o, d_o, matrix.ncols * sizeof(uint), cudaMemcpyDeviceToHost, stream);

    cudaMemcpyAsync(l_response, d_response, matrix.ncols * sizeof(T),
	cudaMemcpyDeviceToHost, stream);

    response.SetLength(matrix.ncols);
    for (int i = 0; i < matrix.ncols; ++i)
    {
	response[i] = to_ZZ_p<T>(l_response[i]);
	if (l_o[i]) response[i] += NTL::to_ZZ_p(NTL::to_ZZ(l_o[i]) << BITS_IN(LIMBS_IN(T)));
	cout << "\n  a''':\t"; print_limbs<T>(response[i]);
    }
	cout << "\n";
}

int main(int argc, char ** argv)
{
    int nstreams = 1;

    if (argc < 3)
    {
	cout << "Usage: " << argv[0] << " VALUES ROWS COLS\n\n";
	return 1;
    }

    time_t t0 = time(0);
    NTL::SetSeed(to_ZZ(t0));
    cout << "seed: " << t0 << "\n";

    struct SparseMatrix<uintX> matrix;
    NTL::ZZ modulus;
    cout << argv[1] << " " << argv[2] << " "  << argv[3] << endl;
    initMatrix(argv[1], argv[2], argv[3], modulus, matrix);
    NTL::ZZ_p::init(modulus);

    struct BarretParams<uintX> barret;
    initBarret<uintX>(modulus, barret);

    cout << "Modulus length: " << NTL::NumBits(modulus) << " bits, NNZ Values: " << matrix.nvals << ", Rows(p): " << matrix.nrows << ", Columns (r): " << matrix.ncols << endl;

    uintX * l_query, * d_query;
    cudaMallocHost((void**)&l_query, nstreams * matrix.nrows * sizeof(uintX));
    cudaMalloc((void**)&d_query, nstreams * matrix.nrows * sizeof(uintX));

    uintX * l_response, * d_response;
    cudaMallocHost((void**)&l_response, nstreams * matrix.ncols * sizeof(uintX));
    cudaMalloc((void**)&d_response, nstreams * matrix.ncols * sizeof(uintX));

    cudaStream_t * streams = new cudaStream_t[nstreams];
    for (int i = 0; i < nstreams; ++i) cudaStreamCreate(&streams[i]);

    NTL::vec_vec_ZZ_p responses(INIT_SIZE, nstreams,
	NTL::vec_ZZ_p(INIT_SIZE, matrix.ncols));
    for (int i = 0; i < nstreams * matrix.nrows; i++)
    {
	to_uint<uintX>(NTL::rep(NTL::random_ZZ_p()), l_query[i]);
    }
cout << "!!!\n";
    std::atomic<int> cnt = ATOMIC_VAR_INIT(0);
    auto start = std::chrono::high_resolution_clock::now();
    std::chrono::nanoseconds onesec{1000000000};
//    while (std::chrono::duration_cast<std::chrono::duration<int,std::nano>>(std::chrono::high_resolution_clock::now() - start) < onesec)
    {
    	int i = cnt % nstreams;
    	uintX * __l_response = l_response + i * matrix.ncols;
    	uintX * __d_response = d_response + i * matrix.ncols;
    	uintX * __l_query    = l_query    + i * matrix.nrows;
    	uintX * __d_query    = d_query    + i * matrix.nrows;
cout << "!!!\n";
	SpMV_ntl(responses[0], l_query, matrix);
	SpMV_ntl_barret(responses[0], l_query, matrix, barret);

	SpMV<uintX>(responses[i], __l_response, __l_query, __d_response,
	    __d_query, streams[i], matrix, barret);
	std::atomic_fetch_add(&cnt, 1);

	for (int j = 0; j < matrix.nrows; j++)
	{
	    to_uint<uintX>(NTL::rep(NTL::random_ZZ_p()), __l_query[j]);
	}

    }

    // cleanup
    delete [] streams;
    responses.kill();

    cudaFreeHost(l_query);
    cudaFree(d_query);
    cudaFreeHost(l_response);
    cudaFree(d_response);

    freeBarret<uintX>(barret);
    freeMatrix<uintX>(matrix);

    return 0;
}


template <typename T>
void initMatrix(const char * valfile, const char * rowfile,
	const char * colfile, NTL::ZZ & modulus,
	struct SparseMatrix<T> & matrix)
{
    std::ifstream valstream(valfile, std::ifstream::in);
    valstream >> modulus;
    
    cout << "  " << modulus << " " << matrix.nvals << endl;
    matrix.l_vals = (T *)malloc(matrix.nvals * sizeof(T));
    cudaMalloc((void**)&matrix.d_vals, matrix.nvals * sizeof(T));

    std::ifstream rowstream(rowfile, std::ifstream::in);
    rowstream >> matrix.nrows;
    rowstream >> matrix.nvals;//TODO
    matrix.l_rows = (uint *)malloc(matrix.nvals * sizeof(uint));
    cudaMalloc((void**)&matrix.d_rows, matrix.nvals * sizeof(uint));

    std::ifstream colstream(colfile, std::ifstream::in);
    colstream >> matrix.ncols;
    matrix.l_cols = (uint *)malloc((matrix.ncols+1) * sizeof(uint));
    cudaMalloc((void**)&matrix.d_cols, (matrix.ncols+1) * sizeof(uint));



    NTL::ZZ_pPush p(modulus);
    for (int i = 0; i < matrix.nvals; i++)
    {
	NTL::ZZ_p tmp;
	valstream >> tmp;
	to_uint<T>(NTL::rep(tmp), matrix.l_vals[i]);
	rowstream >> matrix.l_rows[i];
    }
    valstream.close();
    rowstream.close();
    cudaMemcpy(matrix.d_vals, matrix.l_vals, matrix.nvals * sizeof(T),
	cudaMemcpyHostToDevice);
    cudaMemcpy(matrix.d_rows, matrix.l_rows, matrix.nvals * sizeof(uint),
	cudaMemcpyHostToDevice);

    for (int i = 0; i < matrix.ncols+1; i++)
    {
	colstream >> matrix.l_cols[i];
    }
    colstream.close();
    cudaMemcpy(matrix.d_cols, matrix.l_cols, (matrix.ncols+1) * sizeof(uint),
	cudaMemcpyHostToDevice);
}

template <typename T>
void freeMatrix(struct SparseMatrix<T> & matrix)
{
    free(matrix.l_vals);
    free(matrix.l_rows);
    free(matrix.l_cols);
    cudaFree(matrix.d_vals);
    cudaFree(matrix.d_cols);
    cudaFree(matrix.d_rows);
}

template <typename T>
void initBarret(const NTL::ZZ & modulus_zz, BarretParams<T> & barret)
{
    barret.l_modulus = modulus_zz;
    barret.l_mu = NTL::power2_ZZ(2 * BITS_PER_LIMB * LIMBS_IN(T)) / modulus_zz;
    T modulus;
    to_uint<T>(modulus_zz, modulus);
    T mu;
    to_uint<T>(barret.l_mu, mu); // loses high order bit (but PTX code compensates)!

    barret.l_subtrahends.SetLength(barret.u);
    T * subtrahends = (T *)malloc(barret.u * 2 * sizeof(T));
    for (int i = 0; i < barret.u; ++i)
    {
	barret.l_subtrahends[i] = ((NTL::to_ZZ(i) << (2*BITS_PER_LIMB*LIMBS_IN(T)))
	    / modulus_zz) * modulus_zz;
	NTL::BytesFromZZ((unsigned char *)&subtrahends[2*i], barret.l_subtrahends[i],
	    2 * sizeof(T));
    }

    cudaMalloc((void**)&barret.d_modulus, sizeof(T));
    cudaMemcpy(barret.d_modulus, &modulus, sizeof(T), cudaMemcpyHostToDevice);

    cudaMalloc((void**)&barret.d_mu, sizeof(T));
    cudaMemcpy(barret.d_mu, &mu, sizeof(T), cudaMemcpyHostToDevice);

    cudaMalloc((void**)&barret.d_subtrahends, 2 * barret.u * sizeof(T));
    cudaMemcpy(barret.d_subtrahends, subtrahends, 2 * barret.u * sizeof(T),
	cudaMemcpyHostToDevice);

    free(subtrahends);
}

template<typename T>
void freeBarret(struct BarretParams<T> & barret)
{
    barret.l_subtrahends.kill();
    barret.l_modulus.kill();
    barret.l_mu.kill();
    cudaFree(barret.d_modulus);
    cudaFree(barret.d_mu);
    cudaFree(barret.d_subtrahends);
}
